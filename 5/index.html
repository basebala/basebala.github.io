<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 3 - Face Morphing</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }
        h1 {
            text-align: center;
            color: #000000;
            padding: 20px;
        }
        h2 {
            text-align: center;
        }
        .description {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: left;
            color: #000000;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .image-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 5px;
            padding: 20px;
            max-width: 1400px;
            margin: 0 auto;
        }
        .image-grid img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.2);
            display: block;
        }
        .image-grid .caption {
            text-align: center;
            margin-top: 5px;
            font-size: 1.5em;
            color: #003366;
        }
        .image-grid .info {
            text-align: center;
            margin-top: 5px;
            font-size: .9em;
            color: #003366;
        }

        .image-grid2 {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 5px;
            padding: 20px;
            max-width: 1400px;
            margin: 0 auto;
        }
        .image-grid2 img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.2);
            display: block;
        }
        .image-grid2 .caption {
            text-align: center;
            margin-top: 5px;
            font-size: 1.5em;
            color: #003366;
        }
        .image-grid2 .info {
            text-align: center;
            margin-top: 5px;
            font-size: .9em;
            color: #003366;
        }
        .extra-credit {
            max-width: 800px;
            margin: 40px auto;
            padding: 20px;
            text-align: center;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .extra-credit h2 {
            color: #003366;
        }
        .extra-credit .image-grid {
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
        }
        .extra-credit .image-grid img {
            height: 200px;
            object-fit: cover;
        }
        .extra-credit p {
            margin-top: 20px;
            font-size: 1.1em;
            color: #000000;
        }
    </style>
</head>
<body>
    <h1>Project 5 - Diffusion - Part A</h1>
    <h2>Sampling from the Model</h2>
    <div class="description">
        <p>For this part, I ran the model on the three prompts twice, with a different number of inference steps each time (20 and then 50). Outputs are displayed below, for the images as well as the upsampled images. The second set of images has slightly higher resolution than the first. All images are pretty accurate with respect to the prompt. The second oil painting seems more like an oil painting to me than the first, however. Also, I chose a seed of 180.</p>
    </div>
    <div class="image-grid">
        <figure>
            <img src="p5_part1_0.png" alt="Cathedral">
            <div class="info">20 Inference Steps</div>
        </figure>
        <figure>
            <img src="p5_part1_0_inf.png" alt="Cathedral">
            <div class="info">50 Inference Steps</div>
        </figure>
    </div>
    <h2>Implementing the Forward Process</h2>
    <div class="description">
        <p>Here, I implemented the forward function which takes in an image im and a timestep t as input to generate a noisy image. Here are the outputs of the test image (Campanile) with timesteps of 250, 500, and 750.</p>
    </div>
    <div class="image-grid2">
        <figure>
            <img src="campanile_250.png" alt="Cathedral">
            <div class="info">Campanile (250 noise level)</div>
        </figure>
        <figure>
            <img src="campanile_500.png" alt="Cathedral">
            <div class="info">Campanile (500 noise level)</div>
        </figure>
        <figure>
            <img src="campanile_750.png" alt="Cathedral">
            <div class="info">Campanile (750 noise level)</div>
        </figure>
    </div>
    <h2>Classical Denoising</h2>
    <div class="description">
        <p>Here, I simply used Gaussian blur filtering to try and remove the noise. I have displayed the outputs for filtering the three noised images from the previous section below. I used parameters of 7, 13, and 17 respectively for the blurring.</p>
    </div>
    <div class="image-grid2">
        <figure>
            <img src="campanile_gauss_250.png" alt="Cathedral">
            <div class="info">Filtered campanile (250 noise level)</div>
        </figure>
        <figure>
            <img src="campanile_gauss_500.png" alt="Cathedral">
            <div class="info">Filtered campanile (500 noise level)</div>
        </figure>
        <figure>
            <img src="campanile_gauss_750.png" alt="Cathedral">
            <div class="info">Filtered campanile (750 noise level)</div>
        </figure>
    </div>
    <h2>One Step Denoising</h2>
    <div class="description">
        <p>Here, I implemented one step denoising and have displayed the outputs of this on the three noised images (250, 500, 750) below. Each set of three is the original image, noised, and denoised version side-by-side.</p>
    </div>
    <div class="image-grid2">
        <figure>
            <img src="campanile_3_250.png" alt="Cathedral">
            <figcaption class="caption">250 Noise Set</figcaption>
        </figure>
        <figure>
            <img src="campanile_3_500.png" alt="Cathedral">
            <figcaption class="caption">500 Noise Set</figcaption>
        </figure>
        <figure>
            <img src="campanile_3_750.png" alt="Cathedral">
            <figcaption class="caption">750 Noise Set</figcaption>
        </figure>
    </div>
    <h2>Iterative Denoising</h2>
    <div class="description">
        <p>I implemented iterative denoising here and have displayed below the results of every fifth loop of denoising, as well as the final results (final denoised image, one-step denoised, and noised image).</p>
    </div>
    <div class="image-grid">
        <figure>
            <img src="iterative_loop_4.png" alt="Cathedral">
            <div class="info">Loop 4</div>
        </figure>
        <figure>
            <img src="iterative_loop_9.png" alt="Cathedral">
            <div class="info">Loop 9</div>
        </figure>
        <figure>
            <img src="iterative_loop_13.png" alt="Cathedral">
            <div class="info">Loop 14</div>
        </figure>
        <figure>
            <img src="iterative_loop_17.png" alt="Cathedral">
            <div class="info">Loop 19</div>
        </figure>
        <figure>
            <img src="final_iterative.png" alt="Cathedral">
            <div class="info">Final Image</div>
        </figure>
        <figure>
            <img src="one_step_iterative.png" alt="Cathedral">
            <div class="info">One-Step Image</div>
        </figure>
        <figure>
            <img src="noised_iterative.png" alt="Cathedral">
            <div class="info">Noised Image</div>
        </figure>
    </div>
    <h2>Diffusion Model Sampling</h2>
    <div class="description">
        <p>Here, I generated 5 high-quality images from scratch by using i_start = 0 and passing in random noise.</p>
    </div>
    <figure>
        <img src="5_high_quality.png" alt="Cathedral">
        <div class="info">5 Generations</div>
    </figure>
    <h2>Classifier Free Guidance</h2>
    <div class="description">
        <p>Here, I implemented a function for iterative denoising but with CFG. I have attached 5 images of high-quality photos here.</p>
    </div>
    <figure>
        <img src="5_cfg.png" alt="Cathedral">
        <div class="info">5 Generations</div>
    </figure>
    <h2>Final Images</h2>
    <div class="description">
        <p>I created the features with normalization and flattening, using a 40x40 grid around keypoints (downsized by scale of 5). I then did automatic feature matching, using threshold of .7 for NN and threshold of 3.5 for inliers. Finally, after computing the best homography with 4-point RANSAC, I used this and made a call to my mosaic function from 4A to create final images as displayed below. Furthermore, I displayed the manually computed mosaics (manually created keypoints) below the automatics for reference.</p>
    </div>
    <div class="image-grid2">
        <figure>
            <img src="lunar_1.jpg" alt="Cathedral">
            <figcaption class="caption">First Lunar</figcaption>
        </figure>
        <figure>
            <img src="lunar_2.jpg" alt="Cathedral">
            <figcaption class="caption">Second Lunar</figcaption>
        </figure>
        <figure>
            <img src="auto_lunar_mosaic.jpg" alt="Cathedral">
            <figcaption class="caption">Lunar Auto Mosaic</figcaption>
        </figure>
        <figure>
            <img src="bed_first.jpg" alt="Cathedral">
            <figcaption class="caption">First Bed</figcaption>
        </figure>
        <figure>
            <img src="bed_second.jpg" alt="Cathedral">
            <figcaption class="caption">Second Bed</figcaption>
        </figure>
        <figure>
            <img src="auto_bed_mosaic.jpg" alt="Cathedral">
            <figcaption class="caption">Bed Auto Mosaic</figcaption>
        </figure>
        <figure>
            <img src="vlsb_1.jpg" alt="Cathedral">
            <figcaption class="caption">First VLSB</figcaption>
        </figure>
        <figure>
            <img src="vlsb_2.jpg" alt="Cathedral">
            <figcaption class="caption">Second VLSB</figcaption>
        </figure>
        <figure>
            <img src="auto_vlsb_mosaic.jpg" alt="Cathedral">
            <figcaption class="caption">VLSB Auto Mosaic</figcaption>
        </figure>
        <figure>
            <img src="lunar_mosaic.jpg" alt="Cathedral">
            <figcaption class="caption">Manual Lunar</figcaption>
        </figure>
        <figure>
            <img src="bed_mosaic.jpg" alt="Cathedral">
            <figcaption class="caption">Manual Bed</figcaption>
        </figure>
        <figure>
            <img src="vlsb_mosaic.jpg" alt="Cathedral">
            <figcaption class="caption">Manual VLSB</figcaption>
        </figure>
    </div>
    <h2>Bells and Whistles - Rotation Invariance</h2>
    <div class="description">
        <p>I used SIFT detection here to detect keypoints and then create features that were rotation invariant. Below I have displayed sushis, along with both normal blending of the sushis (my standard function) and blending with rotation-invariant features. With rotation-invariance, it is far better.</p>
    </div>
    <div class="image-grid">
        <figure>
            <img src="new_sushi.jpg" alt="Cathedral">
            <div class="info">Sushi</div>
        </figure>
        <figure>
            <img src="new_sushi_angle.jpg" alt="Cathedral">
            <div class="info">Sushi Angle</div>
        </figure>
        <figure>
            <img src="sushi_standard.jpg" alt="Cathedral">
            <div class="info">Sushi without Rotation-Invariance</div>
        </figure>
        <figure>
            <img src="rot_sushi.jpg" alt="Cathedral">
            <div class="info">Sushi with Rotation-Invariance</div>
        </figure>
    </div>
    <h2>Bells and Whistles - Panorama</h2>
    <div class="description">
        <p>To create a panoramic image with automatic detection of image order, I used a current homography matrix which I updated at each step. To obtain which images to place in which order, I created a matching graph, through which feature strengths detected which images to place in which order. Finally, once this order was determined, the current homography loop would add each image onto the canvas until complete.</p>
    </div>
    <div class="image-grid">
        <figure>
            <img src="pano_v_1.jpg" alt="Cathedral">
            <div class="info">VLSB 1</div>
        </figure>
        <figure>
            <img src="pano_v_2.jpg" alt="Cathedral">
            <div class="info">VLSB 2</div>
        </figure>
        <figure>
            <img src="pano_v_3.jpg" alt="Cathedral">
            <div class="info">VLSB 3</div>
        </figure>
        <figure>
            <img src="final_pano.jpg" alt="Cathedral">
            <div class="info">Panoramic VLSB</div>
        </figure>
    </div>
    <h2>Bells and Whistles 4A - Circle</h2>
    <div class="description">
        <p>I tried morphing images into a circular shape instead of a square. To do this, I created 10 equidistant points on a circle using basic trigonometry in Python. I then had the user choose 10 equidistant points using a circlfy.py file, for then morphing the shape into a circle. Here is a flower without this circular morph and with, as well as sushi bowl.</p>
    </div>
    <div class="image-grid">
        <figure>
            <img src="petaly_flower.jpg" alt="Cathedral">
            <div class="info">Flower no circle</div>
        </figure>
        <figure>
            <img src="circle_federer.jpg" alt="Cathedral">
            <div class="info">Circle flower</div>
        </figure>
        <figure>
            <img src="new_sushi_angle.jpg" alt="Cathedral">
            <div class="info">Sushi without circle (bowl)</div>
        </figure>
        <figure>
            <img src="circle_sushi.jpg" alt="Cathedral">
            <div class="info">Circular sushi bowl</div>
        </figure>
    </div>
</body>
</html>
